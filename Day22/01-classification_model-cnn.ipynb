{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<font color=\"red\">注</font>: 使用 tensorboard 可视化需要安装 tensorflow (TensorBoard依赖于tensorflow库，可以任意安装tensorflow的gpu/cpu版本)\n",
    "\n",
    "```shell\n",
    "pip install tensorflow-cpu\n",
    "```"
   ],
   "id": "e0329ef317080fbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:28:15.743750Z",
     "start_time": "2025-02-04T06:28:11.202691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "    \n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 42\n"
   ],
   "id": "7424b3e4bbba33f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.0\n",
      "numpy 2.0.2\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.0\n",
      "torch 2.5.1+cpu\n",
      "cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据准备",
   "id": "6ddd1c40795ec4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:30:39.352508Z",
     "start_time": "2025-02-04T06:30:39.264818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# fashion_mnist图像分类数据集\n",
    "train_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# torchvision 数据集里没有提供训练集和验证集的划分\n",
    "# 这里用 random_split 按照 11 : 1 的比例来划分数据集\n",
    "train_ds, val_ds = random_split(train_ds, [55000, 5000], torch.Generator().manual_seed(seed))"
   ],
   "id": "a8a05b85f4746f7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:31:01.784756Z",
     "start_time": "2025-02-04T06:31:01.780393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import Normalize\n",
    "\n",
    "# 遍历train_ds得到每张图片，计算每个通道的均值和方差\n",
    "def cal_mean_std(ds):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img, _ in ds:\n",
    "        mean += img.mean(dim=(1, 2))\n",
    "        std += img.std(dim=(1, 2))\n",
    "    mean /= len(ds)\n",
    "    std /= len(ds)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# print(cal_mean_std(train_ds))\n",
    "# 0.2860， 0.3205\n",
    "transforms = nn.Sequential(\n",
    "    Normalize([0.2856], [0.3202])\n",
    ") # 对每个通道进行标准化"
   ],
   "id": "163b2497ee4d356d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:31:11.918772Z",
     "start_time": "2025-02-04T06:31:11.899849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img, label = train_ds[0]\n",
    "img.shape, label"
   ],
   "id": "d1fbbd3c81640ad3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:35:09.111889Z",
     "start_time": "2025-02-04T06:35:09.107738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "# 从数据集到dataloader\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ],
   "id": "3dd4a6f54d82184e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义模型",
   "id": "661f66ab6fb7303e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:35:11.149152Z",
     "start_time": "2025-02-04T06:35:11.144771Z"
    }
   },
   "cell_type": "code",
   "source": "128*9",
   "id": "23cdb07bfcbbd8e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:50:58.807013Z",
     "start_time": "2025-02-04T06:50:58.784268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        初始化CNN模型。\n",
    "        :param activation: 激活函数类型，默认为\"relu\"。可选值：\"relu\" 或 \"selu\"。\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        # 根据传入的激活函数类型，选择相应的激活函数\n",
    "        self.activation = F.relu if activation == \"relu\" else F.selu\n",
    "\n",
    "        # 定义卷积层\n",
    "        # 输入通道数：1（灰度图像），输出通道数：32，卷积核大小：3x3，填充：1（保持尺寸不变）\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        # 输入通道数：32，输出通道数：32，卷积核大小：3x3，填充：1\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        # 池化层，池化核大小：2x2，步长：2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 输入通道数：32，输出通道数：64，卷积核大小：3x3，填充：1\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        # 输入通道数：64，输出通道数：64，卷积核大小：3x3，填充：1\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # 输入通道数：64，输出通道数：128，卷积核大小：3x3，填充：1\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        # 输入通道数：128，输出通道数：128，卷积核大小：3x3，填充：1\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        # 展平层，将多维输入一维化\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 全连接层1，输入特征数：128*3*3，输出特征数：128\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
    "        # 全连接层2，输入特征数：128，输出特征数：10（对应10个类别）\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        使用Xavier均匀分布初始化卷积层和全连接层的权重。\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        定义前向传播过程。\n",
    "        :param x: 输入张量，形状为(batch_size, 1, 28, 28)\n",
    "        :return: 输出张量，形状为(batch_size, 10)\n",
    "        \"\"\"\n",
    "        # 第一组卷积层 -> 激活函数 -> 池化层\n",
    "        x = self.pool(self.activation(self.conv2(self.activation(self.conv1(x)))))  # 1 * 28 * 28 -> 32 * 14 * 14\n",
    "        print(x.shape)  # 打印中间层输出形状\n",
    "        # 第二组卷积层 -> 激活函数 -> 池化层\n",
    "        x = self.pool(self.activation(self.conv4(self.activation(self.conv3(x)))))  # 32 * 14 * 14 -> 64 * 7 * 7\n",
    "        print(x.shape)  # 打印中间层输出形状\n",
    "        # 第三组卷积层 -> 激活函数 -> 池化层\n",
    "        x = self.pool(self.activation(self.conv6(self.activation(self.conv5(x)))))  # 64 * 7 * 7 -> 128 * 3 * 3\n",
    "        print(x.shape)  # 打印中间层输出形状\n",
    "        # 展平层\n",
    "        x = self.flatten(x)  # 128 * 3 * 3 -> 1152\n",
    "        # 全连接层1 -> 激活函数\n",
    "        x = self.activation(self.fc1(x))  # 1152 -> 128\n",
    "        # 全连接层2\n",
    "        x = self.fc2(x)  # 128 -> 10\n",
    "        return x\n",
    "\n",
    "# 打印模型的参数信息\n",
    "for idx, (key, value) in enumerate(CNN().named_parameters()):\n",
    "    print(f\"{key}\\t参数数量: {np.prod(value.shape)}\")\n"
   ],
   "id": "5c22956dee8319e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\t参数数量: 288\n",
      "conv1.bias\t参数数量: 32\n",
      "conv2.weight\t参数数量: 9216\n",
      "conv2.bias\t参数数量: 32\n",
      "conv3.weight\t参数数量: 18432\n",
      "conv3.bias\t参数数量: 64\n",
      "conv4.weight\t参数数量: 36864\n",
      "conv4.bias\t参数数量: 64\n",
      "conv5.weight\t参数数量: 73728\n",
      "conv5.bias\t参数数量: 128\n",
      "conv6.weight\t参数数量: 147456\n",
      "conv6.bias\t参数数量: 128\n",
      "fc1.weight\t参数数量: 147456\n",
      "fc1.bias\t参数数量: 128\n",
      "fc2.weight\t参数数量: 1280\n",
      "fc2.bias\t参数数量: 10\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:51:09.796178Z",
     "start_time": "2025-02-04T06:51:09.791580Z"
    }
   },
   "cell_type": "code",
   "source": "3*3*32    *32",
   "id": "c097bd55fe9957a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#练习不同尺寸的卷积核，padding，stride的效果\n",
    "class CNN1(nn.Module):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super(CNN, self).__init__()\n",
    "        self.activation = F.relu if activation == \"relu\" else F.selu\n",
    "        #输入通道数，图片是灰度图，所以是1，图片是彩色图，就是3，输出通道数，就是卷积核的个数（32,1,28,28）\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5,padding=2,stride=2)\n",
    "        #输入x(32,32,28,28) 输出x(32,32,28,28)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2) #池化核大小为2（2*2），步长为2\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # input shape is (28, 28, 1) so the fc1 layer in_features is 128 * 3 * 3\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10) #输出尺寸（32,10）\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化全连接层、卷积层的权重 W\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        act = self.activation\n",
    "        x=act(self.conv1(x)) # 1 * 28 * 28 -> 32 * 28 * 28\n",
    "        print(x.shape)\n",
    "        # x=act(self.conv2(x)) # 32 * 28 * 28 -> 32 * 28 * 28\n",
    "        # print(x.shape)\n",
    "        # x = self.pool(x) # 32 * 28 * 28 -> 32 * 14 * 14\n",
    "        # print(x.shape)\n",
    "        # x=act(self.conv3(x)) # 32 * 14 * 14 -> 64 * 14 * 14\n",
    "        # print(x.shape)\n",
    "        # x=act(self.conv4(x)) # 64 * 14 * 14 -> 64 * 14 * 14\n",
    "        # print(x.shape)\n",
    "        # x = self.pool(x) # 32 * 14 * 14 -> 64 * 7 * 7\n",
    "        # print(x.shape)\n",
    "        # x=act(self.conv5(x)) # 64 * 7 * 7 -> 128 * 7 * 7\n",
    "        # print(x.shape)\n",
    "        # x=act(self.conv6(x)) # 128 * 7 * 7 -> 128 * 7 * 7\n",
    "        # print(x.shape)\n",
    "        # x = self.pool(x) # 128 * 7 * 7 -> 128 * 3 * 3\n",
    "        # print(x.shape)\n",
    "        # x = self.flatten(x) # 128 * 3 * 3 ->1152\n",
    "        # x = act(self.fc1(x)) # 1152 -> 128\n",
    "        # x = self.fc2(x) # 128 -> 10\n",
    "        return x\n"
   ],
   "id": "7910cd0cfca5392a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T06:51:56.313993Z",
     "start_time": "2025-02-04T06:51:56.249997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation = \"relu\"\n",
    "model = CNN(activation)\n",
    "# model.to(device)\n",
    "img = torch.randn(1, 1, 28, 28)\n",
    "model(img)"
   ],
   "id": "c98176da4b3bbbb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 64, 7, 7])\n",
      "torch.Size([1, 128, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0228, -0.1328, -0.0574, -0.0596,  0.0018,  0.0389,  0.0346, -0.0524,\n",
       "         -0.1359, -0.0186]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation=\"relu\"):\n",
    "        super(CNN, self).__init__()\n",
    "        self.activation = F.relu if activation == \"relu\" else F.selu\n",
    "        #输入通道数，图片是灰度图，所以是1，图片是彩色图，就是3，输出通道数，就是卷积核的个数（32,1,28,28）\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        #输入x(32,32,28,28) 输出x(32,32,28,28)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2) #池化核大小为2（2*2），步长为2\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        # input shape is (28, 28, 1) so the fc1 layer in_features is 128 * 3 * 3\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10) #输出尺寸（32,10）\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化全连接层、卷积层的权重 W\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        act = self.activation\n",
    "        x=act(self.conv1(x)) # 1 * 28 * 28 -> 32 * 28 * 28\n",
    "        print(x.shape)\n",
    "        x=act(self.conv2(x)) # 32 * 28 * 28 -> 32 * 28 * 28\n",
    "        print(x.shape)\n",
    "        x = self.pool(x) # 32 * 28 * 28 -> 32 * 14 * 14\n",
    "        print(x.shape)\n",
    "        x=act(self.conv3(x)) # 32 * 14 * 14 -> 64 * 14 * 14\n",
    "        print(x.shape)\n",
    "        x=act(self.conv4(x)) # 64 * 14 * 14 -> 64 * 14 * 14\n",
    "        print(x.shape)\n",
    "        x = self.pool(x) # 32 * 14 * 14 -> 64 * 7 * 7\n",
    "        print(x.shape)\n",
    "        x=act(self.conv5(x)) # 64 * 7 * 7 -> 128 * 7 * 7\n",
    "        print(x.shape)\n",
    "        x=act(self.conv6(x)) # 128 * 7 * 7 -> 128 * 7 * 7\n",
    "        print(x.shape)\n",
    "        x = self.pool(x) # 128 * 7 * 7 -> 128 * 3 * 3\n",
    "        print(x.shape)\n",
    "        x = self.flatten(x) # 128 * 3 * 3 ->1152\n",
    "        x = act(self.fc1(x)) # 1152 -> 128\n",
    "        x = self.fc2(x) # 128 -> 10\n",
    "        return x\n",
    "\n",
    "\n",
    "for idx, (key, value) in enumerate(CNN().named_parameters()):\n",
    "    print(f\"{key}\\tparamerters num: {np.prod(value.shape)}\") # 打印模型的参数信息\n"
   ],
   "id": "b9128466015dd6fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "activation = \"relu\"\n",
    "model = CNN(activation)\n",
    "# model.to(device)\n",
    "# img = torch.randn(1, 1, 28, 28)\n",
    "# model(img)"
   ],
   "id": "5a40f9508cc5d79f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
